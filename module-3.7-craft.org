#+TITLE: Module 3.7 - Craft
#+SUBTITLE: 2nd stage of 'chat, craft, and scale' process
#+AUTHOR: Peter Jun Koh
#+EMAIL: gopeterjun@naver.com
#+DESCRIPTION: use Claude chat to craft prompts for Claude Code
#+KEYWORDS: LLM, claude code, prompting,
#+LANGUAGE: en

* Summary

- Created on: [2025-07-27 Sun]
- Last Updated: [2025-08-02 Sat 22:35]

The *craft* stage of /chat, craft and scale/ entails implementation,
details like what libraries to use, project folder structure, project
configuration, and deployment.

In this stage as well, Claude can be a big help.

* Topics

** Thinking about developer ergonomics and interfaces

Prof. White believes that good ergonomics and interfaces that he would
like to use personally tend to have better outcomes when Claude
generates code for such interfaces.

Here is Prof. White's prompt:

#+begin_quote
Design three different ~fluent~ clients in Javascript for interacting with
the API. Only show me the interface usage through examples.
#+end_quote

And here is Claude's response:

*Design 1: Method Chaining Builder*

#+begin_src js
  // Basic execution
  const result = await client
    .createJob()
    .withTask("Create a simple Python web server")
    .withTimeout(300)
    .execute();

  // With file uploads
  const result = await client
    .createJob()
    .withTask("Analyze this CSV file")
    .withFiles([{ name: "data.csv", content: csvData }])
    .withTimeout(600)
    .execute();

  // Job monitoring
  const job = await client
    .job("job_a7b3c9d1")
    .status();

  const logs = await client
    .job("job_a7b3c9d1")
    .logs();
#+end_src

*Design 2: Resource-based Fluent API*

#+begin_src js
  // Job creation and execution
  const job = await client.jobs.create({
    task: "Create a simple Python web server",
    timeout: 300
  });

  // Job operations
  const status = await client.jobs(job.id).get();
  const logs = await client.jobs(job.id).logs.get();
  const artifacts = await client.jobs(job.id).artifacts.list();

  // File operations
  await client.jobs(job.id).files.upload("data.csv", csvData);
  const serverFile = await client.jobs(job.id).artifacts.download("server.py");

  // List and filter jobs
  const allJobs = await client.jobs.list();
  const runningJobs = await client.jobs.list({ status: "running" });

  // Job lifecycle
  await client.jobs(job.id).cancel();
  await client.jobs(job.id).delete();
#+end_src

*Design 3: Promise-based Fluent API*

#+begin_src js
  // Simple execution with automatic polling
  const result = await client
    .execute("Create a simple Python web server")
    .withTimeout(300)
    .waitForCompletion();

  // Async execution with callbacks
  client
    .execute("Process large dataset")
    .withFiles([{ name: "data.csv", content: csvData }])
    .onProgress((progress) => console.log(`Progress: ${progress}%`))
    .onLog((log) => console.log(log.message))
    .onComplete((result) => console.log("Done!", result))
    .start();

  // Manual job control
  const execution = client
    .execute("Long running task")
    .withTimeout(1800);

  const jobId = await execution.start();
  const status = await execution.status();
  const logs = await execution.logs();
  const artifacts = await execution.artifacts();
#+end_src

Claude describes the following snippet above as follows:

#+begin_quote
This is JavaScript code for a client library that handles job execution
with different patterns - synchronous with polling, asynchronous with
callbacks, and manual job control. The code shows methods for executing
tasks, handling timeouts, processing files, monitoring progress, and
retrieving job status and artifacts.
#+end_quote

When looking at these different fluent clients for our API, we should think
about what client would be easier to work with for ourselves? A less
complicated and more succinct client that helps us avoid API client usage
errors would also do the same for Claude!

** Use Claude Chat to generate a prompt for Claude Code

Prof. White has decided to go with the ~fluent~ client from *Design 1*,
which uses a /method chaining builder/.

We can use Claude's chat interface to help us create a good prompt that
=claude= can then use to write the code for us.

Here is Prof. White's prompt to the Claude chat interface:

#+begin_quote
  I like version 1 of all the design aspects.

  Now, write a complete prompt that I can cut/paste into Claude Code to get
  it to implement this.
#+end_quote

The generated prompt can be found in the following section

** Claude Code HTTP API Wrapper Implementation (generated by Claude Chat)

Please implement a complete HTTP API wrapper for Claude Code with the
following specifications:

*** API Design (Resource-Oriented REST)

Implement these 9 HTTP routes:

| Verb   | Endpoint                           | Description                     |
|--------+------------------------------------+---------------------------------|
| POST   | /api/v1/jobs                       | Create new execution job        |
| GET    | /api/v1/jobs                       | List all jobs (with pagination) |
| GET    | /api/v1/jobs/{id}                  | Get specific job details        |
| DELETE | /api/v1/jobs/{id}                  | Cancel/delete job               |
| GET    | /api/v1/jobs/{id}/logs             | Get job execution logs          |
| GET    | /api/v1/jobs/{id}/artifacts        | List job output artifacts       |
| GET    | /api/v1/jobs/{id}/artifacts/{name} | Download specific artifact      |
| POST   | /api/v1/jobs/{id}/files            | Upload files to job workspace   |
| GET    | /api/v1/health                     | Health check endpoint           |

*** Core Requirements

**** Job Creation (POST /api/v1/jobs)
- Accept JSON payload with:
  - =task= (string)
  - =files= (array)
  - =timeout= (number)
- Return =201= created with job object containing:
  - =id=
  - =status=
  - =created_at=
  - =links=
- Queue job for execution using Claude Code
- Generate unique job IDs

**** Job Execution Engine
- Execute jobs asynchronously using Claude Code CLI
- Support job states:
  - =queued=
  - =running=
  - =completed=
  - =failed=
  - =cancelled=
- Capture execution logs in real-time
- Collect output artifacts (files created during execution)
- Handle timeouts and cancellation
- Store job metadata and results

**** File Management
- Support file uploads to job workspace before execution
- Collect and store artifacts generated during execution
- Provide file download endpoints for artifacts
- Handle multipart form data for file uploads

*** Data Models

#+begin_src js
  // Job Object
    {
        "id": "job_a7b3c9d1",
        "status": "completed",
        "task": "Create a simple Python web server",
        "created_at": "2025-07-16T14:23:45Z",
        "updated_at": "2025-07-16T14:24:12Z",
        "started_at": "2025-07-16T14:23:47Z",
        "completed_at": "2025-07-16T14:24:12Z",
        "timeout": 300,
        "files": [],
        "progress": 100,
        "duration": 25,
        "exit_code": 0,
        "summary": "Successfully created a Python web server using Flask with basic routing and error handling",
        "artifacts": [
            {
                "name": "server.py",
                "size": 1248,
                "type": "application/x-python",
                "created_at": "2025-07-16T14:24:08Z",
            }
        ],
        "links": {
          "self": "/api/v1/jobs/job_a7b3c9d1",
          "logs": "/api/v1/jobs/job_a7b3c9d1/logs",
          "artifacts": "/api/v1/jobs/job_a7b3c9d1/artifacts",
          "files": "/api/v1/jobs/job_a7b3c9d1/files"
        }
  }
#+end_src

*** Technical Implementation

**** Technology Stack
- *Framework*: ~Express.js~ or ~Fastify~ for HTTP server
- *Storage*: File system for job data and artifacts, JSON files for metadata
- *Process Management*: Child processes for Claude Code execution
- *File Handling*: ~Multer~ for multipart uploads
- *Logging*: ~Winston~ or similar for structured logging

**** Security & Validation
- Input validation for all endpoints
- File upload size limits (50MB max)
- Job timeout enforcement
- Sanitize file names and paths
- Rate limiting (100 requests per hour per IP)

**** Error Handling
- Proper HTTP status codes
- Structured error responses
- Graceful handling of Claude Code failures

**** Directory Structure

#+begin_src text
  claude-code-api/
  ├── src/
  │   ├── controllers/
  │   │   ├── jobs.js
  │   │   └── health.js
  │   ├── services/
  │   │   ├── executor.js
  │   │   └── storage.js
  │   ├── middleware/
  │   │   ├── validation.js
  │   │   └── auth.js
  │   ├── models/
  │   │   └── job.js
  │   ├── routes/
  │   │   └── index.js
  │   └── app.js
  ├── storage/
  │   ├── jobs/
  │   ├── artifacts/
  │   └── workspaces/
  ├── package.json
  └── README.md
#+end_src

**** JavaScript Fluent Client

Also implement a Javascript client library with method chaining:

#+begin_src js
  // Usage examples the client should support:
  const result = await client
    .createJob()
    .withTask("Create a simple Python web server")
    .withTimeout(300)
    .execute();

  const job = await client
    .job("job_a7b3c9d1")
    .status();

  const logs = await client
    .job("job_a7b3c9d1")
    .logs();

  await client
    .job("job_a7b3c9d1")
    .uploadFile("config.json", configData);

  const artifact = await client
    .job("job_a7b3c9d1")
    .downloadArtifact("server.py");
#+end_src

**** Implementation Notes
1. *Claude Code Integration*: Use =child_process.spawn= to execute ~claude
   code~ CLI commands
2. *Job Isolation*: Create separate workspace directories for each job
3. *Async Processing*: Use job queues for background execution
4. *Logging*: Capture both API logs and Claude Code execution logs
5. *Monitoring*: Include health check endpoint with system status
6. *Documentation*: Generate OpenAPI/Swagger documentation
7. *Testing*: Include unit tests for core functionality

**** Deliverables

1. Complete HTTP API server with all 9 endpoints
2. Job execution engine that integrates with Claude Code
3. File upload/download functionality
4. JavaScript ~fluent~ client library
5. =package.json= with all dependencies
6. =README= with setup and usage instructions
7. Example usage scripts

Please implement this as a production-ready ~Node.js~ application with
proper error handling, logging, and documentation.

** Review of the /Big Bang/ prompt

The prompt that Claude Chat generated in the previous section was just an
excerpt! We can save this prompt in =CLAUDE.md= and then create a new
=git= repo for the /Claude Code HTTP API Wrapper/ project and place this
=CLAUDE.md= in the new repo with our project requirements. =claude= could
then refer to this file while implementing the project. There is a greater
chance that Claude will generate quality code with less bugs if it has
access to well-organized and specific project requirements like the one
we generated with the help of Claude Chat.

Sometimes, however, it can be better to split up a big prompt into smaller,
more modular ones depending on the limitations of your agentic coding
tool. As of July 2025, the /Big Bang/ prompt might be difficult for Claude
Code, but I think /Ampcode/ from Sourcegraph with its sub-agents feature,
might be able to tackle the entire project in one go with the help of
sub-agents.

** Ex: generate multiple modular prompts from the Big Bang prompt

#+begin_quote
This is a lot to do at once. Let's break this plan up into a series of
incremental steps. We want each step to end in a testable state and a
commit. You choose how many increments.
#+end_quote

Claude chat then generates the following modular prompts for us that we can
then feed to =claude=:

*** Claude Code HTTP API Wrapper - Incremental Implementation Plan

We'll build this API wrapper in 8 incremental steps, each ending in a
testable state and a commit. Here's the implementation plan:

**** Step 1: Project Setup and Basic Server
*Goal*: Create a basic Express.js server with health check endpoint

*Implementation*:
- Initialize Node.js project with =package.json=
- Install Express.js and basic dependencies
- Create basic server structure
- Implement =GET /api/v1/health= endpoint
- Add basic middleware (JSON parsing, CORS)
- Add basic error handling

*Test*: Server starts on port ~3000~, health check returns =200 OK=

*Commit*: "Initial server setup with health check endpoint"

**** Step 2: In-Memory Job Storage and Job Creation
*Goal*: Implement job creation and storage without Claude Code execution

*Implementation*:
- Create Job model/class with all required fields
- Implement in-memory job storage
- Add =POST /api/v1/jobs= endpoint (creates job but doesn't execute)
- Add =GET /api/v1/jobs/{id}= endpoint
- Add =GET /api/v1/jobs= endpoint (list all jobs)
- Jobs start in ~"queued"~ status

*Test*: Can create jobs, retrieve them by ID, and list all jobs

*Commit*: "Add job creation and retrieval endpoints with in-memory storage"

**** Step 3: Basic Claude Code Execution
*Goal*: Execute Claude Code and capture basic results

*Implementation*:
- Create executor service using =child_process.spawn=
- Implement basic job execution (changes status from queued -> running ->
  completed/failed)
- Execute jobs immediately after creation for now
- Capture basic execution results (exit code, duration)
- Add job status updates and completion timestamps

*Test*: Jobs execute Claude Code tasks and update status appropriately

*Commit*: "Add basic Claude Code execution with status tracking"

**** Step 4: Logging System
*Goal*: Capture and serve execution logs

*Implementation*:
- Add logging capture during Claude Code execution
- Store logs in job objects
- Implement =GET /api/v1/jobs/{id}/logs= endpoint
- Add structured logging with timestamps and levels
- Include both API logs and Claude Code output

*Test*: Can retrieve detailed execution logs for any job

*Commit*: "Add comprehensive logging system for job execution"

**** Add'l steps 5 to 8

Prof. White doesn't show us these steps but notes that sometimes you can
split up a big prompt into steps, but sometimes you can leave this up
to Claude's discretion and tell it that if it gets confused, to refer back
to the project requirements doc.

** Example of prompt for drilling down into Step One

*Prompt*

Let's think of library options for this step. Let's also think of the
detailed implementation / coding conventions / package structure and
other things we need to decide now.

What are the key decisions? (Below is Step 1 which Claude generated
earlier).

#+begin_src markdown
  ### Claude Code HTTP API Wrapper - Incremental Implementation Plan

  We'll build this API wrapper in 8 incremental steps, each ending in a
  testable state and a commit. Here's the implementation plan:

  #### Step 1: Project Setup and Basic Server
  ,**Goal**: Create a basic Express.js server with health check endpoint

  ,**Implementation**:
  - Initialize Node.js project with `package.json`
  - Install Express.js and basic dependencies
  - Create basic server structure
  - Implement `GET /api/v1/health` endpoint
  - Add basic middleware (JSON parsing, CORS)
  - Add basic error handling

  ,**Test**: Server starts on port `3000`, health check returns `200 OK`

  ,**Commit**: "Initial server setup with health check endpoint"
#+end_src

Prof. White says he uses prompts like this to discover new libraries that
he might not know about already. And below is Claude Chat's response:

*** 1. Web Framework Choice

*Options*:
- *Express.js* - Most popular, extensive ecosystem, familiar
- *Fastify* - Better performance, built-in validation, TypeScript-first
- *Koa.js* - Smaller, modern async/await support
- *Hapi.js* - Enterprise-focused, built-in features

*Recommendation: Express.js* - Best balance of familiarity, ecosystem, and
documentation

*** 2. Language & Type Safety

*Options*:
- *JavaScript* - Simpler setup, faster development
- *TypeScript* - Better type safety, IDE support, maintainability

*Recommendation: JavaScript* for now (can migrate to TypeScript later if needed)

*** 3. Package Structure & Organization

*Options*:
- *Flat structure* - All files in =src/=
- *Domain-driven* - Organized by business domain (jobs, health, etc.)
- *Layered architecture* - Separated by technical concerns (controllers,
  services, models)

*Recommendation: Layered architecture for clarity*:

#+begin_src text
  claude-code-api/
  ├── src/
  │   ├── controllers/       # HTTP request handlers
  │   ├── services/          # Business logic
  │   ├── models/            # Data models
  │   ├── middleware/        # Express middleware
  │   ├── routes/            # Route definitions
  │   ├── utils/             # Utility functions
  │   └── app.js             # Main application
  ├── tests/
  ├── storage/               # File storage
  ├── package.json
  └── README.md
#+end_src

** Example of prompt for digging into app configuration

Prof. White makes another prompt to make sure that all the pieces fit well
together in a cohesive configuration.

*Prompt*

Propose three different configurations and discuss the pros/cons. Would
any of these details influence our architectural choices?

Claude's responses are below:

*** Configuration 1: Minimal & Fast
*Philosophy*: Get to MVP quickly with proven, simple tools

*Stack*:
- *Framework*: Express.js
- *Language*: JavaScript (ES6+)
- *Validation*: Basic manual validation
- *Logging*: =console.log= + Morgan for HTTP
- *Error Handling*: Simple try/catch + global handler
- *Testing*: Jest + Supertest
- *Config*: Environment variables only
- *Process*: nodemon (dev), node (prod)

*Pros*:
- Fastest to implement and iterate
- Minimal learning curve
- Fewer dependencies to manage
- Quick debugging and testing
- Small bundle size

*Cons*:
- Manual validation is error-prone
- Console logging lacks structure
- Harder to maintain as complexity grows
- Limited error context
- No built-in security features

*Architectural Impact*:
- Simple, flat structure works well
- Manual validation logic scattered throughout controllers
- Error handling becomes inconsistent without structure

*** Configuration 2: Production-Ready & Robust
*Philosophy*: Enterprise-grade with comprehensive tooling

*Stack*:
- *Framework*: Express.js + comprehensive middleware
- *Language*: TypeScript
- *Validation*: Joi with custom middleware
- *Logging*: Winston + Morgan with structured logging
- *Error Handling*: Custom error classes + global handler
- *Testing*: Jest + Supertest + coverage
- *Config*: Config files + environment overrides
- *Security*: Helmet, rate limiting, input sanitization
- *Process*: ~PM2~ with clustering

*Pros*:
- Type safety prevents runtime errors
- Comprehensive error handling and logging
- Built-in security features
- Structured validation
- Production-ready from day one
- Better IDE support and refactoring

*Cons*:
- Slower initial development
- More complex setup and configuration
- Steeper learning curve
- More dependencies to manage
- Potentially over-engineered for simple use cases

*Architectural Impact*:
- Requires more sophisticated layered architecture
- Type definitions influence API design
- Validation schemas become first-class citizens
- Error handling becomes centralized and consistent

*** Configuration 3: Performance & Modern
*Philosophy*: Optimized for speed and modern JavaScript practices

*Stack*:
- *Framework*: Fastify (faster than Express)
- *Language*: JavaScript with modern features
- *Validation*: Fastify's built-in JSON Schema validation
- *Logging*: Pino (high-performance logging)
- *Error Handling*: Fastify's built-in error handling
- *Testing*: Vitest (faster than Jest)
- *Config*: Environment-based with validation
- *Security*: Fastify plugins ecosystem
- *Process*: Built-in clustering support

*Pros*:
- Superior performance (2x faster than Express)
- Built-in validation with JSON Schema
- Modern async/await throughout
- Excellent plugin ecosystem
- Better TypeScript support out of the box
- Structured logging by default

*Cons*:
- Smaller community than Express
- Different mental model from Express
- Fewer third-party integrations
- Less familiar to most developers
- Plugin-based architecture can be complex

*Architectural Impact*:
- Plugin-based architecture influences code organization
- Schema-first approach affects API design
- Async/await patterns throughout
- Performance considerations influence data flow

** Conclusion

Now we have generated much of the implementation details and also prompts
that we can feed to Claude Code. We are not micromanaging the AI line by
line of code, but are crafting constraints, style guides, and guidelines
for our big prompt to improve the chances that Claude will build what we
want it to build.
